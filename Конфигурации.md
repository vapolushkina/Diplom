### Terraform

```
terraform {
  required_providers {
    yandex = {
      source = "yandex-cloud/yandex"
    }
  }
  required_version = ">= 0.13"
}
provider "yandex" {
  token     = "y0_AgAAAAAClG8vAATuwQAAAADsRS14qyJKZVanTRW11ix3Q_N4iY2YAAI"
  cloud_id  = "b1gbeem934f657rmna3m"
  folder_id = "b1gkktlocu9hinvnod1t"
}

#############
resource "yandex_vpc_network" "network-1" {
  name = "network1"
}
resource "yandex_vpc_subnet" "subnet-1" {
  name           = "subnet1"
  zone           = "ru-central1-a"
  v4_cidr_blocks = ["192.168.10.0/24"]
  network_id     = yandex_vpc_network.network-1.id
}
resource "yandex_vpc_subnet" "subnet-2" {
  name           = "subnet2"
  zone           = "ru-central1-b"
  v4_cidr_blocks = ["192.168.11.0/24"]
  network_id     = yandex_vpc_network.network-1.id
}

############# группа безопасности

resource "yandex_vpc_security_group" "security" {
   name        = "security"
   description = "Description for security group"
   network_id  = yandex_vpc_network.network-1.id
   ingress {
     protocol       = "TCP"
     description    = "grafana"
     v4_cidr_blocks = ["0.0.0.0/0"]
     port           = 3000
   }
   ingress {
     protocol       = "TCP"
     description    = "kibana"
     v4_cidr_blocks = ["0.0.0.0/0"]
     port           = 5601
   }
   ingress {
     protocol       = "TCP"
     description    = "application load balancer"
     v4_cidr_blocks = ["0.0.0.0/0"]
     port           = 80
   }
   ingress {
     protocol       = "TCP"
     description    = "SSH-permission"
     v4_cidr_blocks = ["192.168.0.0/16"]
     port           = 22
   }
   egress {
     protocol       = "ANY"
     description    = "Rule description 2"
     v4_cidr_blocks = ["0.0.0.0/0"]
     from_port      = 0
     to_port        = 65535
   }
 }
 resource "yandex_vpc_security_group" "bastion" {
   name        = "bastion"
   description = "Description for bastion group"
   network_id  = yandex_vpc_network.network-1.id
   ingress {
     protocol       = "TCP"
     description    = "bastion"
     v4_cidr_blocks = ["0.0.0.0/0"]
     port           = 22
   }
   egress {
     protocol       = "ANY"
     description    = "Rule description 2"
     v4_cidr_blocks = ["0.0.0.0/0"]
     from_port      = 0
     to_port        = 65535
   }
 }

############# первый вэб

resource "yandex_compute_instance" "vm-1" {
  name                      = "vm1"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
       ip_address = "192.168.10.10"
    nat       = false
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-1" {
   value = yandex_compute_instance.vm-1.network_interface.0.ip_address
 }
output "external_ip_address_vm-1" {
   value = yandex_compute_instance.vm-1.network_interface.0.nat_ip_address
 }

############ второй вэб

resource "yandex_compute_instance" "vm-2" {
  name                      = "vm2"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-b"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-2.id
         ip_address = "192.168.11.10"
    nat       = false
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-2" {
   value = yandex_compute_instance.vm-2.network_interface.0.ip_address
 }
output "external_ip_address_vm-2" {
   value = yandex_compute_instance.vm-2.network_interface.0.nat_ip_address
 }
################ Prometheus

resource "yandex_compute_instance" "vm-3" {
  name                      = "prom"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
        ip_address = "192.168.10.11"
    nat       = false
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-3" {
   value = yandex_compute_instance.vm-3.network_interface.0.ip_address
 }
output "external_ip_address_vm-3" {
   value = yandex_compute_instance.vm-3.network_interface.0.nat_ip_address
 }

############ Grafana

resource "yandex_compute_instance" "vm-4" {
  name                      = "grafana"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
          ip_address = "192.168.10.12"
    nat       = true
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-4" {
   value = yandex_compute_instance.vm-4.network_interface.0.ip_address
 }
output "external_ip_address_vm-4" {
   value = yandex_compute_instance.vm-4.network_interface.0.nat_ip_address
 }

############ Elastic

resource "yandex_compute_instance" "vm-5" {
  name                      = "elastic"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "4"
    core_fraction = "15"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
        ip_address = "192.168.10.13"
    nat       = false
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-5" {
   value = yandex_compute_instance.vm-5.network_interface.0.ip_address
 }
output "external_ip_address_vm-5" {
   value = yandex_compute_instance.vm-5.network_interface.0.nat_ip_address
 }

############ Kibana

resource "yandex_compute_instance" "vm-6" {
  name                      = "kibana"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
        ip_address = "192.168.10.14"
    nat       = true
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-6" {
   value = yandex_compute_instance.vm-6.network_interface.0.ip_address
 }
output "external_ip_address_vm-6" {
   value = yandex_compute_instance.vm-6.network_interface.0.nat_ip_address
 }

############ bastion

resource "yandex_compute_instance" "vm-7" {
  name                      = "bastion"
  allow_stopping_for_update = true
  platform_id               = "standard-v1"
  zone                      = "ru-central1-a"
  resources {
    cores         = "2"
    memory        = "2"
    core_fraction = "5"
  }
  boot_disk {
    initialize_params {
      image_id = "fd87q4jvf0vdho41nnvr"
      size     = 5
    }
  }
  network_interface {
    subnet_id = yandex_vpc_subnet.subnet-1.id
        ip_address = "192.168.10.15"
    nat       = true 
  }
  metadata = {
    user-data = "${file("cloud-init.yaml")}"
 }
}
output "internal_ip_address_vm-7" {
   value = yandex_compute_instance.vm-7.network_interface.0.ip_address
 }
output "external_ip_address_vm-7" {
   value = yandex_compute_instance.vm-7.network_interface.0.nat_ip_address
 }

########## таргет группа

resource "yandex_alb_target_group" "foo" {
  name           = "target-group"
  target {
    subnet_id    = yandex_vpc_subnet.subnet-1.id
    ip_address   = yandex_compute_instance.vm-1.network_interface.0.ip_address
  }
  target {
    subnet_id    = yandex_vpc_subnet.subnet-2.id
    ip_address   = yandex_compute_instance.vm-2.network_interface.0.ip_address
  }
}

########## бэкэнд группа

resource "yandex_alb_backend_group" "backend-group" {
  name                     = "backend-group"
  session_affinity {
    connection {
      source_ip = false
    }
  }
  http_backend {
    name                   = "backend-group"
    weight                 = 1
    port                   = 80
    target_group_ids       = [yandex_alb_target_group.foo.id]
    load_balancing_config {
      panic_threshold      = 90
    }
    healthcheck {
      timeout              = "10s"
      interval             = "2s"
      healthy_threshold    = 10
      unhealthy_threshold  = 15
      http_healthcheck {
        path               = "/"
      }
    }
  }
}

######### http роутер

resource "yandex_alb_http_router" "tf-router" {
  name          = "router"
  labels        = {
    tf-label    = "tf-label-value"
    empty-label = ""
  }
}
resource "yandex_alb_virtual_host" "my-virtual-host" {
  name                    = "virtual-host"
  http_router_id          = yandex_alb_http_router.tf-router.id
  route {
    name                  = "test"
    http_route {
      http_route_action {
        backend_group_id  = yandex_alb_backend_group.backend-group.id
        timeout           = "60s"
      }
    }
  }
}

######### балансер

resource "yandex_alb_load_balancer" "balancer" {
  name        = "balancer"
  network_id  = yandex_vpc_network.network-1.id
  allocation_policy {
    location {
      zone_id   = "ru-central1-a"
      subnet_id = yandex_vpc_subnet.subnet-1.id   
    }
  }
  listener {
    name = "list1"
    endpoint {
      address {
        external_ipv4_address {
        }
      }
      ports = [ 80 ]
    }
    http {
      handler {
        http_router_id = yandex_alb_http_router.tf-router.id
      }
    }
  }
}


###########снапшот

resource "yandex_compute_snapshot_schedule" "default" {

  name = "snap"
  schedule_policy {
    expression = "00 19 ? * *"
  }
  snapshot_count = 5
  disk_ids = [yandex_compute_instance.vm-1.boot_disk[0].disk_id,
              yandex_compute_instance.vm-2.boot_disk[0].disk_id,
              yandex_compute_instance.vm-3.boot_disk[0].disk_id,
              yandex_compute_instance.vm-4.boot_disk[0].disk_id,
              yandex_compute_instance.vm-5.boot_disk[0].disk_id, 
              yandex_compute_instance.vm-6.boot_disk[0].disk_id,           
              yandex_compute_instance.vm-7.boot_disk[0].disk_id,
             ]
}
```
---

### Ansible

`playbook`

```
---
- hosts: web
  become: true
  become_method: sudo
  become_user: root
  remote_user: admin
  roles:
   - role: nginx
   - role: node-exporter

- hosts: prom
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: prometheus

- hosts: grafana
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: grafana

- hosts: elastic
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: elastic

- hosts: kibana
  user: admin
  become: true
  become_method: sudo
  become_user: root
  roles:
    - role: kibana

- hosts: web
  become: true
  become_method: sudo
  become_user: root
  remote_user: admin
  roles:
   - role: filebeat

```

`nginx`

*1. tasks*

```
- name: ensure nginx is at the latest version
  apt: name=nginx state=latest
  become: yes

- name: start nginx
  service:
     name: nginx
     state: started
  become: yes

- name: replace nginx.conf
  template:
     src=templates/nginx.conf
     dest=/etc/nginx/nginx.conf

- name: replace default
  template:
     src=templates/default
     dest=/etc/nginx/sites-enabled/default

- name: copy the content of the web site
  copy:
    src: /etc/ansible/roles/nginx/static/
    dest: /var/www/html

- name: restart nginx
  service:
     name: nginx
     state: restarted
  become: yes
```
*2. vars*

```
---
# vars file for roles/nginx
worker_processes: auto
worker_connections: 2048
client_max_body_size: 512M
```
*3. static*

```
<html>
  <head>
<meta charset="UTF-8">
<center><h1>Всего хорошего!</h1><center>
<img src="https://github.com/vapolushkina/vapolushkina/assets/121248099/5b6845f>
  </head>
  </html>
```

`node-exporter`

*1. tasks*

```
---
# tasks file for roles/node-exporter

- name: check if node exporter exist
  stat:
    path: "{{ node_exporter_bin }}"
  register: __check_node_exporter_present

- name: create node exporter user
  user:
    name: "{{ node_exporter_user }}"
    append: true
    shell: /usr/sbin/nologin
    system: true
    create_home: false

- name: create node exporter config dir
  file:
    path: "{{ node_exporter_dir_conf }}"
    state: directory
    owner: "{{ node_exporter_user }}"
    group: "{{ node_exporter_group }}"

- name: if node exporter exist get version
  shell: "cat /etc/systemd/system/node_exporter.service | grep Version | sed s/'.*Version '//g"
  when: __check_node_exporter_present.stat.exists == true
  changed_when: false
  register: __get_node_exporter_version

- name: download and unzip node exporter if not exist
  unarchive:
    src: "https://github.com/prometheus/node_exporter/releases/download/v{{ node_exporter_version }}/node_exporter-{{ node_exporter_version }}.linux-amd64.tar.gz"
    dest: /tmp/
    remote_src: yes
    validate_certs: no

- name: move the binary to the final destination
  copy:
    src: "/tmp/node_exporter-{{ node_exporter_version }}.linux-amd64/node_exporter"
    dest: "{{ node_exporter_bin }}"
    owner: "{{ node_exporter_user }}"
    group: "{{ node_exporter_group }}"
    mode: 0755
    remote_src: yes
  when: __check_node_exporter_present.stat.exists == false or not __get_node_exporter_version.stdout == node_exporter_version

- name: clean
  file:
    path: /tmp/node_exporter-{{ node_exporter_version }}.linux-amd64/
    state: absent

- name: install service
  template:
    src: node.j2
    dest: /etc/systemd/system/node_exporter.service
    owner: root
    group: root
    mode: 0755

- name: service always started
  systemd:
    name: node_exporter
    state: started
    enabled: yes
```
*2. vars*

```
---
# vars file for roles/node-exporter

node_exporter_version: "1.6.1"
node_exporter_bin: /usr/local/bin/node_exporter
node_exporter_user: expo
node_exporter_group: "{{ node_exporter_user }}"
node_exporter_dir_conf: /etc/node_exporter

nginx_log_exporter : 1.9.2
```
*3. templates*

```
[Unit]
Description=Node Exporter Version {{ node_exporter_version }}
After=network-online.target
[Service]
User={{ node_exporter_user }}
Group={{ node_exporter_user }}
Type=simple
ExecStart={{ node_exporter_bin }}
[Install]
WantedBy=multi-user.target
```

`prometheus`

*1. tasks*

main.yml
```
---
# tasks file for roles/prometheus

- name: Install Prometheus
  include_tasks: tasks/prometheus.yml
```
prometheus.yml
```
- name: Create User prometheus
  user:
    name: prometheus
    create_home: no
    shell: /bin/false
- name: Create directories for prometheus
  file:
    path: "{{ item }}"
    state: directory
    owner: prometheus
    group: prometheus
  loop:
    - '/tmp/prometheus'
    - '/etc/prometheus'
    - '/var/lib/prometheus'
- name: Download And Unzipped Prometheus
  unarchive:
    src: https://github.com/prometheus/prometheus/releases/download/v{{ prometheus_version }}/prometheus-{{ prometheus_version }}.linux-amd64.tar.gz
    dest: /tmp/prometheus
    creates: /tmp/prometheus/prometheus-{{ prometheus_version }}.linux-amd64
    remote_src: yes
- name: Copy Bin Files From Unzipped to Prometheus
  copy: 
    src: /tmp/prometheus/prometheus-{{ prometheus_version }}.linux-amd64/{{ item }}
    dest: /usr/local/bin/
    remote_src: yes
    mode: preserve
    owner: prometheus
    group: prometheus
  loop: [ 'prometheus', 'promtool' ]
- name: Copy Conf Files From Unzipped to Prometheus
  copy: 
    src: /tmp/prometheus/prometheus-{{ prometheus_version }}.linux-amd64/{{ item }}
    dest: /etc/prometheus/
    remote_src: yes
    mode: preserve
    owner: prometheus
    group: prometheus
  loop: [ 'console_libraries', 'consoles', 'prometheus.yml' ]
- name: Add template
  template:
    src=templates/prometheus.yml
    dest=/etc/prometheus/prometheus.yml
- name: Create File for Prometheus Systemd
  template:
    src=templates/prometheus.service
    dest=/etc/systemd/system/
- name: Systemctl Prometheus Start
  systemd:
    name: prometheus
    state: started
    enabled: yes
```
*2. vars*

```
---
# vars file for roles/prometheus
prometheus_version : 2.23.0
```
*3. static*

prometheus.service
```
[Unit]
Description=Prometheus Service
After=network.target
[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
--config.file /etc/prometheus/prometheus.yml \
--storage.tsdb.path /var/lib/prometheus/ \
--web.console.templates=/etc/prometheus/consoles \
--web.console.libraries=/etc/prometheus/console_libraries
ExecReload=/bin/kill -HUP $MAINPID
Restart=on-failure
[Install]
WantedBy=multi-user.target
```

prometheus.yml
```
# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).
# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
   - job_name: 'node_exporter_clients'
     scrape_interval: 5s
     static_configs:
      - targets:
          - 192.168.10.10:9100
          - 192.168.11.10:9100
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
   - job_name: 'nginx_exporter'
     scrape_interval: 5s
     static_configs:
      - targets: 
          - 192.168.10.10:4040
          - 192.168.11.10:4040
```

`grafana`

*1. tasks*

```
---

# tasks file for roles/grafana
- name: Download grafana
  get_url:
    url: https://dl.grafana.com/oss/release/grafana_10.0.2_amd64.deb
    dest: /tmp/
- name: Install grafana
  command: "dpkg -i /tmp/grafana_10.0.2_amd64.deb"
- name: Systemctl grafana  Start
  systemd:
    name: grafana-server
    state: started
    enabled: yes
```

`elasticsearch`

*1. tasks*

```
---
# tasks file for roles/elastic
- name: Create User elasticsearch
  user:
    name: elastic
    create_home: no
    shell: /bin/false
- name: Create directories for elasticsearch
  file:
    path: "/tmp/elasticsearch"
    state: directory
- name: Download elasticsearch
  copy:
    src: "/etc/ansible/roles/elastic/static/elasticsearch-8.8.2-amd64.deb"
    dest: /tmp/elasticsearch
- name: Install java
  apt:
    name=default-jre
    state=latest
- name: Install elasticsearch
  apt:
    deb: "/tmp/elasticsearch/elasticsearch-8.8.2-amd64.deb"
```

`filebeat`

*1. tasks*

```
---
# tasks file for roles/filebeat
- name: Create directories for filebeat
  file:
    path: "/tmp/filebeat"
    state: directory
- name: Download filebeat
  copy:
    src: "/etc/ansible/roles/kibana/static/filebeat-8.8.2-amd64.deb"
    dest: /tmp/filebeat
- name: Install filebeat
  apt:
    deb: "/tmp/filebeat/filebeat-8.8.2-amd64.deb"
- name: Copy template
  copy:
    src: "/etc/ansible/roles/filebeat/templates/filebeat.yml"
    dest: /etc/filebeat
- name: Copy module
  copy:
    src: "/etc/ansible/roles/filebeat/templates/nginx.yml"
    dest: /etc/filebeat/modules.d/
- name: Copy ca
  copy:
    src: "/etc/ansible/roles/kibana/static/http_ca.crt"
    dest: /etc/filebeat
```

`kibana`

*1. tasks*

```
---
# tasks file for roles/kibana
- name: Create directories for kibana
  file:
    path: "/tmp/kibana"
    state: directory
- name: Download kibana
  copy:
    src: "/etc/ansible/roles/kibana/static/kibana-8.8.2-amd64.deb"
    dest: /tmp/kibana
- name: Install kibana
  apt:
    deb: "/tmp/kibana/kibana-8.8.2-amd64.deb"
- name: Copy template
  copy:
    src: "/etc/ansible/roles/kibana/templates/kibana.yml"
    dest: /etc/kibana
- name: Create directories for ca
  file:
    path: "/etc/kibana/certs/"
    state: directory
- name: Copy ca
  copy:
    src: "/etc/ansible/roles/kibana/static/http_ca.crt"
    dest: /etc/kibana/certs/
```
